{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Environment setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DSP_CACHEBOOL=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(encoding=\"utf-8\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Define the data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Label(str, Enum):\n",
    "    HAM = \"ham\"\n",
    "    SPAM = \"spam\"\n",
    "    SMISHING = \"smishing\"\n",
    "\n",
    "\n",
    "class Input(BaseModel):\n",
    "    text: str = Field(description=\"SMS text to be classified\")\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "    label: Label = Field(description=\"The predicted label for the SMS text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"../data/sms_phishing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy import Example\n",
    "\n",
    "examples = []\n",
    "for r in df.iter_rows(named=True):\n",
    "    examples.append(\n",
    "        Example(\n",
    "            input=Input(text=r[\"TEXT\"]), output=Output(label=r[\"LABEL\"].lower())\n",
    "        ).with_inputs(\"input\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PCT = 0.96\n",
    "VAL_PCT = 0.02\n",
    "TEST_PCT = 0.02\n",
    "train = examples[: int(len(examples) * TRAIN_PCT)]\n",
    "val = examples[\n",
    "    int(len(examples) * TRAIN_PCT) : int(len(examples) * (TRAIN_PCT + VAL_PCT))\n",
    "]\n",
    "test = examples[int(len(examples) * (TRAIN_PCT + VAL_PCT)) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Model connection\n",
    "### Models\n",
    "* llama3.2:3b\n",
    "* llama3.1:8b\n",
    "* gemma2:9b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# MODEL = \"llama3.2:3b-instruct-fp16\"\n",
    "# MODEL = \"gemma2:2b\"\n",
    "MODEL = \"qwen2.5:0.5b\"\n",
    "# MODEL = \"gemma2:9b\"\n",
    "\n",
    "lm = dspy.OllamaLocal(\n",
    "    model=MODEL,\n",
    ")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "dspy.settings.configure(lm=lm)\n",
    "dspy.configure(experimental=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMSClassifierSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Given an SMS text, predict whether it is ham, spam, or smishing.\n",
    "    Output only the predicted label.\n",
    "    \"\"\"\n",
    "\n",
    "    input: Input = dspy.InputField()\n",
    "    output: Output = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMSClassifier(dspy.Module):\n",
    "    def __init__(self, lm):\n",
    "        self.lm = lm\n",
    "        super().__init__()\n",
    "        dspy.configure(lm=lm)\n",
    "        self.generate_answer = dspy.TypedPredictor(\n",
    "            SMSClassifierSignature, max_retries=10\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.generate_answer(input=input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_classifier = SMSClassifier(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_helpers import validate_answer\n",
    "from langfuse_extensions import EvaluateWithLangfuse\n",
    "\n",
    "# from evaluation_helpers import EvaluateWithLangfuse\n",
    "evaluator = EvaluateWithLangfuse(devset=test, num_threads=1, display_progress=True)\n",
    "evaluator(sms_classifier, metric=validate_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# Set up the optimizer: we want to \"bootstrap\" (i.e., self-generate) 8-shot examples of your program's steps.\n",
    "# The optimizer will repeat this 10 times (plus some initial attempts) before selecting its best attempt on the devset.\n",
    "config = dict(\n",
    "    max_bootstrapped_demos=4,\n",
    "    max_labeled_demos=8,\n",
    "    num_candidate_programs=16,\n",
    "    num_threads=1,\n",
    "    max_errors=10,\n",
    ")\n",
    "\n",
    "teleprompter = BootstrapFewShotWithRandomSearch(metric=validate_answer, **config)\n",
    "optimized_program = teleprompter.compile(sms_classifier, trainset=train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EvaluateWithLangfuse(devset=test, num_threads=1, display_progress=True)\n",
    "evaluator(optimized_program, metric=validate_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_program.save(\"programs/sms_classifier-qwen2.5-0.5b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
