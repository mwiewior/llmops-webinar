{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Automatic prompt optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DSP_CACHEBOOL=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Prepare train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./module-00-data-prep.ipynb\n",
    "train = train\n",
    "val = val\n",
    "test = test\n",
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "MODEL = \"qwen2.5:1.5b\"\n",
    "\n",
    "\n",
    "lm = dspy.OllamaLocal(\n",
    "    model=MODEL,\n",
    ")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Program definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sms_classifier import SMSClassifier\n",
    "\n",
    "sms_classifier = SMSClassifier(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Setup prompt optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "from evaluation_helpers import validate_answer\n",
    "\n",
    "config = dict(\n",
    "    max_bootstrapped_demos=4,\n",
    "    max_labeled_demos=8,\n",
    "    num_candidate_programs=24,\n",
    "    num_threads=1,\n",
    "    max_errors=10,\n",
    ")\n",
    "\n",
    "teleprompter = BootstrapFewShotWithRandomSearch(metric=validate_answer, **config)\n",
    "optimized_program = teleprompter.compile(sms_classifier, trainset=train[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "... this process can take some time - mostly depending on the train dataset size and number of candidate programs. Beware of the costs if using a commercial model!\n",
    "\n",
    "Once the process is done and you're satisfied with the results you can save a model for later use.\n",
    "```python\n",
    "optimized_program.save(f\"programs/sms_classifier-{MODEL}.json\")\n",
    "```\n",
    "Take a sneak peek into its internals..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Let's start with loading the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_classifier = SMSClassifier(lm)\n",
    "optimized_classifier.load(f\"programs/sms_classifier-{MODEL}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from evaluation_helpers import validate_answer\n",
    "\n",
    "from notebooks.cybersecurity.langfuse_extensions import EvaluateWithLangfuse\n",
    "\n",
    "session = f\"Run-{MODEL}-optim-{int(datetime.now().timestamp())}\"\n",
    "print(session)\n",
    "evaluator = EvaluateWithLangfuse(\n",
    "    devset=test, num_threads=1, display_progress=True, run_id=session\n",
    ")\n",
    "evaluator(optimized_classifier, metric=validate_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Load previous saved program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## After running the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_helpers import calculate_metrics, fetch_traces\n",
    "from sms_classifier import Label\n",
    "\n",
    "classes = [l.value for l in Label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-qwen2.5:7b-optim-1729433657\n",
    "traces_qwen25_7_optim = fetch_traces(run_id=\"Run-qwen2.5:7b-optim-1729433657\")\n",
    "metrics_qwen25_7_optim = calculate_metrics(traces_qwen25_7_optim, classes)\n",
    "metrics_qwen25_7_optim[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-gemma2:9b-optim-1729434900\n",
    "traces_gemma2_9_optim = fetch_traces(run_id=\"Run-gemma2:9b-optim-1729434900\")\n",
    "metrics_gemma2_9_optim = calculate_metrics(traces_gemma2_9_optim, classes)\n",
    "metrics_gemma2_9_optim[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-llama3.1:8b-optim-1729436001\n",
    "traces_llama31_8_optim = fetch_traces(run_id=\"Run-llama3.1:8b-optim-1729436001\")\n",
    "metrics_llama31_8_optim = calculate_metrics(traces_llama31_8_optim, classes)\n",
    "metrics_llama31_8_optim[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-qwen2.5:1.5b-optim-1729436454\n",
    "traces_qwen25_1_5_optim = fetch_traces(run_id=\"Run-qwen2.5:1.5b-optim-1729436454\")\n",
    "metrics_qwen25_1_5_optim = calculate_metrics(traces_qwen25_1_5_optim, classes)\n",
    "metrics_qwen25_1_5_optim[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-qwen2.5:3b-optim-1729437009\n",
    "traces_qwen25_3_optim = fetch_traces(run_id=\"Run-qwen2.5:3b-optim-1729437009\")\n",
    "metrics_qwen25_3_optim = calculate_metrics(traces_qwen25_3_optim, classes)\n",
    "metrics_qwen25_3_optim[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-qwen2.5:0.5b-optim-1729437842\n",
    "traces_qwen25_0_5_optim = fetch_traces(run_id=\"Run-qwen2.5:0.5b-optim-1729437842\")\n",
    "metrics_qwen25_0_5_optim = calculate_metrics(traces_qwen25_0_5_optim, classes)\n",
    "metrics_qwen25_0_5_optim[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-gpt-4o-ai-factory-1729432239\n",
    "traces_gpt_4 = fetch_traces(run_id=\"Run-gpt-4o-ai-factory-1729432239\")\n",
    "metrics_gpt_4 = calculate_metrics(traces_gpt_4, classes)\n",
    "metrics_gpt_4[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_optim = dict()\n",
    "metrics_optim[\"qwen2.5:0.5b\"] = metrics_qwen25_0_5_optim[\"macro\"]\n",
    "metrics_optim[\"qwen2.5:1.5b\"] = metrics_qwen25_1_5_optim[\"macro\"]\n",
    "metrics_optim[\"qwen2.5:3b\"] = metrics_qwen25_3_optim[\"macro\"]\n",
    "metrics_optim[\"qwen2.5:7b\"] = metrics_qwen25_7_optim[\"macro\"]\n",
    "metrics_optim[\"gemma2:9b\"] = metrics_gemma2_9_optim[\"macro\"]\n",
    "metrics_optim[\"llama3.1:8b\"] = metrics_llama31_8_optim[\"macro\"]\n",
    "metrics_optim[\"gpt-4o-ai-factory-baseline\"] = metrics_gpt_4[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_helpers import plot_metrics\n",
    "\n",
    "plot_metrics(\n",
    "    metrics_optim, [\"Precision\", \"Recall\", \"F1\"], \"Scores by model after optimization\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
